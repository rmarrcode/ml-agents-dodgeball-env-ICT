{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Actor(nn.Module):\n",
    "    def __init__(self, state_dim, action_dim, hidden_size):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(state_dim, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.mu = nn.Linear(hidden_size, action_dim)\n",
    "        self.log_std = nn.Linear(hidden_size, action_dim)\n",
    "\n",
    "    def forward(self, state):\n",
    "        x = torch.relu(self.fc1(state))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        mu = self.mu(x)\n",
    "        log_std = self.log_std(x)\n",
    "        std = torch.exp(log_std)\n",
    "        dist = Normal(mu, std)\n",
    "        return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.parameters at 0x00000171F4B4EEA0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action = Actor(1, 1, 1)\n",
    "action.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SACAgent(nn.Module):\n",
    "    def __init__(self, observation_size, action_size, hidden_size):\n",
    "        super().__init__()\n",
    "        self.actor = Actor(observation_size, action_size, hidden_size)\n",
    "        self.actor_optimizer = optim.Adam(self.actor.parameters(), lr=.007)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'parameters'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 153\u001b[0m\n\u001b[0;32m    149\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m    152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 153\u001b[0m     driver \u001b[38;5;241m=\u001b[39m \u001b[43mDriver\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    154\u001b[0m     driver\u001b[38;5;241m.\u001b[39mmain()\n",
      "Cell \u001b[1;32mIn[12], line 124\u001b[0m, in \u001b[0;36mDriver.__init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    123\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magent_registry \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 124\u001b[0m     sacagent \u001b[38;5;241m=\u001b[39m \u001b[43mSACAgent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservation_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mOBSERVATION_SIZE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maction_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mACTION_SIZE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mHIDDEN_SIZE\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[12], line 92\u001b[0m, in \u001b[0;36mSACAgent.__init__\u001b[1;34m(self, observation_size, action_size, hidden_size)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcritic1_optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcritic1\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mLEARNING_RATE)\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcritic2_optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcritic2\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mLEARNING_RATE)\n\u001b[1;32m---> 92\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactor_optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m(), lr\u001b[38;5;241m=\u001b[39mLEARNING_RATE)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'function' object has no attribute 'parameters'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "# from mlagents_envs.environment import UnityEnvironment\n",
    "# from mlagents_envs.side_channel.engine_configuration_channel import EngineConfigurationChannel\n",
    "# from mlagents_envs.base_env import ActionTuple  \n",
    "# import torch.distributions as D\n",
    "from torch.distributions import Categorical\n",
    "import numpy as np\n",
    "import sys\n",
    "from debug_side_channel import DebugSideChannel\n",
    "from torch.distributions import Normal\n",
    "\n",
    "TRAINING_STEPS = 10000\n",
    "OBSERVATION_SIZE = 6\n",
    "ACTION_SIZE = 5\n",
    "HIDDEN_SIZE = 128\n",
    "LEARNING_RATE = .001\n",
    "UPDATE_PERIOD = 100\n",
    "AGENT_ID_A = 0\n",
    "AGENT_ID_B = 1\n",
    "NO_AGENTS = 2\n",
    "BUFFER_SIZE = 256\n",
    "\n",
    "Unity_Environment = \"C:\\\\Users\\\\rmarr\\\\Documents\\\\ml-agents-dodgeball-env-ICT\"\n",
    "NO_SIMULATIONS = 1\n",
    "TIME_SCALE = 2.0\n",
    "# state\n",
    "# 10 x 10 grid \n",
    "# 0 = nothing 1 = wall 2 = agent position\n",
    "#debug_side_channel = DebugSideChannel()\n",
    "\n",
    "class Actor(nn.Module):\n",
    "    def __init__(self, state_dim, action_dim, hidden_size):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(state_dim, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.mu = nn.Linear(hidden_size, action_dim)\n",
    "        self.log_std = nn.Linear(hidden_size, action_dim)\n",
    "\n",
    "    def forward(self, state):\n",
    "        x = torch.relu(self.fc1(state))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        mu = self.mu(x)\n",
    "        log_std = self.log_std(x)\n",
    "        std = torch.exp(log_std)\n",
    "        dist = Normal(mu, std)\n",
    "        return dist\n",
    "\n",
    "\n",
    "\n",
    "class SACAgent(nn.Module):\n",
    "    def __init__(self, observation_size, action_size, hidden_size):\n",
    "        super().__init__()\n",
    "        self.actor = Actor(observation_size, action_size, hidden_size)\n",
    "\n",
    "        self.target_critic1.load_state_dict(self.critic1.state_dict())\n",
    "        self.target_critic2.load_state_dict(self.critic2.state_dict())\n",
    "\n",
    "        self.critic1_optimizer = optim.Adam(self.critic1.parameters(), lr=LEARNING_RATE)\n",
    "        self.critic2_optimizer = optim.Adam(self.critic2.parameters(), lr=LEARNING_RATE)\n",
    "        self.actor_optimizer = optim.Adam(self.actor.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "\n",
    "    def q1(self, state, action):\n",
    "        q_in = torch.cat((state, torch.one_hot(action)))\n",
    "        x = self.fc1(q_in)\n",
    "        x = torch.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = torch.softmax(x, dim=0)\n",
    "        return x \n",
    "        \n",
    "    def q2(self, state, action):\n",
    "        q_in = torch.cat((state, torch.one_hot(action)))\n",
    "        x = self.fc1(q_in)\n",
    "        x = torch.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = torch.softmax(x, dim=0)\n",
    "        return x \n",
    "\n",
    "    # maybe switch to paper's implementation\n",
    "    def actor(self, state, no_simulations):\n",
    "        x = self.fc5(state)\n",
    "        x = torch.relu(x)\n",
    "        x = self.fc6(x)\n",
    "        x = torch.softmax(x, dim=0)\n",
    "        categorical_dist = Categorical(logits=x[0])\n",
    "        return categorical_dist.sample((no_simulations,))\n",
    "\n",
    "\n",
    "class Driver():\n",
    "    def __init__(self):\n",
    "        self.agent_registry = []\n",
    "        sacagent = SACAgent(observation_size=OBSERVATION_SIZE, action_size=ACTION_SIZE, hidden_size=HIDDEN_SIZE)\n",
    "        \n",
    "\n",
    "    def main(self):\n",
    "        #print(f'behavior_name {behavior_name}')\n",
    "        #spec = env.behavior_specs[behavior_name]\n",
    "        #print(f'spec {spec}')\n",
    "        #self.env.reset()\n",
    "        # debug_messages = debug_side_channel.get_and_clear_messages()\n",
    "        # print(debug_messages)\n",
    "        # for message in debug_messages:\n",
    "        #     print(f\"Received from Unity: {message}\")\n",
    "\n",
    "        # TODO one optimizer or 2?\n",
    "\n",
    "        #self.env.reset()\n",
    "        for episode in range(TRAINING_STEPS):\n",
    "            # Agent actions\n",
    "            [self.replay_buffer_resistry[agent_id].add(self.transition_tuple(agent_id)) for agent_id in range(NO_AGENTS)]\n",
    "            # done = any([self.replay_buffer_resistry[agent_id].done() for agent_id in range(NO_AGENTS)])\n",
    "            # if done:\n",
    "            #     self.env.reset()\n",
    "            if (episode + 1) % BUFFER_SIZE == 0:\n",
    "                [self.train(agent_id) for agent_id in range(NO_AGENTS)]\n",
    "\n",
    "        self.env.close()\n",
    "        \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    driver = Driver()\n",
    "    driver.main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
